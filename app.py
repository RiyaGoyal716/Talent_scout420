import streamlit as st
from streamlit_chat import message
import os
import time
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv
import requests
from langdetect import detect

# ----------------------------
# Load Environment Variables
# ----------------------------
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# ----------------------------
# Set Custom Page Config
# ----------------------------
st.set_page_config(page_title="TalentScout AI - Hiring Assistant", page_icon="ğŸ§ ", layout="centered")

# ----------------------------
# Custom CSS Styling
# ----------------------------
st.markdown("""
    <style>
    body {
        background-color: #f5f7fa;
    }
    .st-emotion-cache-1avcm0n {
        padding-top: 1rem;
    }
    .stChatInputContainer {
        background: #fff;
        border-top: 2px solid #ccc;
    }
    .stButton button {
        background-color: #003366;
        color: white;
        font-weight: bold;
        border-radius: 8px;
    }
    .stMarkdown h1, .stMarkdown h2, .stMarkdown h3 {
        color: #003366;
    }
    .chat-container {
        background-color: #ffffff;
        padding: 1.2rem;
        border-radius: 12px;
        box-shadow: 0px 4px 12px rgba(0,0,0,0.08);
        margin-top: 1rem;
    }
    .info-box {
        background-color: #eaf3ff;
        padding: 0.8rem;
        border-radius: 10px;
        margin-bottom: 10px;
        font-size: 15px;
    }
    </style>
""", unsafe_allow_html=True)

# ----------------------------
# App Header
# ----------------------------
st.markdown("## ğŸ§  TalentScout AI Assistant")
st.caption("Your intelligent virtual recruiter for smarter hiring decisions.")

# ----------------------------
# State Initialization
# ----------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []
if "stage" not in st.session_state:
    st.session_state.stage = "greeting"
if "candidate_info" not in st.session_state:
    st.session_state.candidate_info = {}
if "topic_questions" not in st.session_state:
    st.session_state.topic_questions = []
if "end_chat" not in st.session_state:
    st.session_state.end_chat = False
if "all_responses" not in st.session_state:
    st.session_state.all_responses = []

# ----------------------------
# LLM API Wrapper
# ----------------------------
def generate_llm_response(prompt):
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "llama3-8b-8192",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7
    }
    response = requests.post(GROQ_API_URL, headers=headers, json=data)
    if response.status_code == 401:
        return "âŒ Error: Invalid API key. Please check your GROQ_API_KEY."
    try:
        return response.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        return f"âŒ Error: {e}"

# ----------------------------
# Resume Upload & Processing
# ----------------------------
def extract_text_from_resume(uploaded_file):
    if uploaded_file.type == "application/pdf":
        import fitz
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        return " ".join([page.get_text() for page in doc])
    elif uploaded_file.type == "text/plain":
        return uploaded_file.read().decode("utf-8")
    elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        import docx
        doc = docx.Document(uploaded_file)
        return " ".join([para.text for para in doc.paragraphs])
    else:
        return "Unsupported file type."

def translate_to_english(text):
    prompt = f"""You are a helpful assistant. Translate the following text to English, preserving the meaning and technical terms:\n\n{text}"""
    return generate_llm_response(prompt)

# ----------------------------
# Tech Question Generator
# ----------------------------
def get_technical_questions(topic):
    prompt = f"""
You are an AI interviewer. Generate:
- 3 beginner
- 3 intermediate
- 3 advanced
technical interview questions on the topic: {topic}.
Provide the questions in a clear list format.
"""
    return generate_llm_response(prompt)

# ----------------------------
# Conversation Flow Logic
# ----------------------------
def chat_logic(user_input):
    info = st.session_state.candidate_info
    stage = st.session_state.stage

    if user_input.lower() in ["exit", "quit", "bye", "end"]:
        st.session_state.end_chat = True
        save_data_to_csv()
        return "âœ… Thank you for chatting with TalentScout! Weâ€™ll be in touch shortly. Goodbye! ğŸ‘‹"

    if "generate questions on" in user_input.lower():
        topic = user_input.lower().split("generate questions on")[-1].strip()
        qns = get_technical_questions(topic)
        st.session_state.topic_questions.append((topic, qns))
        st.session_state.all_responses.append({"User Input": user_input, "AI Response": qns})
        return f"Here are your questions on **{topic}**:\n\n{qns}"

    if stage == "greeting":
        st.session_state.stage = "full_name"
        return "ğŸ‘‹ Welcome! Iâ€™m your virtual assistant from TalentScout.\n\nCan I know your **full name**?"

    elif stage == "full_name":
        info["Full Name"] = user_input
        st.session_state.stage = "email"
        return "ğŸ“§ Whatâ€™s your **email address**?"

    elif stage == "email":
        info["Email"] = user_input
        st.session_state.stage = "phone"
        return "ğŸ“ Could you share your **phone number**?"

    elif stage == "phone":
        info["Phone"] = user_input
        st.session_state.stage = "experience"
        return "ğŸ§‘â€ğŸ’» How many **years of experience** do you have?"

    elif stage == "experience":
        info["Experience"] = user_input
        st.session_state.stage = "position"
        return "ğŸ¯ What **position(s)** are you applying for?"

    elif stage == "position":
        info["Position"] = user_input
        st.session_state.stage = "location"
        return "ğŸ“ Where are you **currently located**?"

    elif stage == "location":
        info["Location"] = user_input
        st.session_state.stage = "tech_stack"
        return "ğŸ’» Please list your **tech stack** (e.g., Python, React, MongoDB)..."

    elif stage == "tech_stack":
        info["Tech Stack"] = user_input
        tech_q = get_technical_questions(user_input)
        st.session_state.topic_questions.append((user_input, tech_q))
        st.session_state.all_responses.append({"Tech Stack": user_input, "Questions": tech_q})
        st.session_state.stage = "done"
        return f"ğŸ§ª Here are some questions based on your tech stack:\n\n{tech_q}\n\nâœ… Thatâ€™s all I need for now. You can ask me to generate questions on any topic by typing: 'Generate questions on ...'"

    else:
        return "â“ I didnâ€™t quite get that. You can continue our chat or type 'end' to finish."

# ----------------------------
# Save to CSV
# ----------------------------
def save_data_to_csv():
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    info = st.session_state.candidate_info
    all_qas = st.session_state.all_responses

    df_info = pd.DataFrame([info])
    df_info.to_csv(f"candidate_info_{timestamp}.csv", index=False)

    df_qas = pd.DataFrame(all_qas)
    df_qas.to_csv(f"candidate_qna_{timestamp}.csv", index=False)

# ----------------------------
# Chat Interface
# ----------------------------
with st.container():
    for i, msg in enumerate(st.session_state.messages):
        message(msg["content"], is_user=msg["role"] == "user", key=str(i))

# ----------------------------
# File Upload Section
# ----------------------------
with st.sidebar:
    uploaded_file = st.file_uploader("ğŸ“„ Upload Resume (PDF, DOCX, TXT)", type=["pdf", "txt", "docx"])
    if uploaded_file:
        resume_text = extract_text_from_resume(uploaded_file)
        detected_lang = detect(resume_text)

        if detected_lang != "en":
            st.warning("ğŸŒ Non-English resume detected. Translating to English...")
            translated_resume = translate_to_english(resume_text[:1000])
            st.session_state.candidate_info["Original Language"] = detected_lang
            st.session_state.candidate_info["Translated Resume"] = translated_resume[:300] + "..."
            topic_q = get_technical_questions(translated_resume[:600])
        else:
            translated_resume = resume_text
            topic_q = get_technical_questions(resume_text[:600])

        st.session_state.candidate_info["Resume"] = translated_resume[:300] + "..."
        st.session_state.topic_questions.append(("Resume Content", topic_q))
        st.session_state.all_responses.append({
            "Resume Extract": translated_resume[:300],
            "Questions": topic_q
        })
        st.success("Resume processed. Questions based on resume will appear in chat.")

# ----------------------------
# Chat Input
# ----------------------------
if not st.session_state.end_chat:
    user_prompt = st.chat_input("Type here to talk to TalentScout...")

    if user_prompt:
        st.session_state.messages.append({"role": "user", "content": user_prompt})
        bot_response = chat_logic(user_prompt)
        time.sleep(0.2)
        st.session_state.messages.append({"role": "assistant", "content": bot_response})
        st.experimental_rerun()
else:
    st.success("Conversation has ended. Refresh the page to restart.")
    with st.expander("ğŸ“„ Candidate Summary"):
        for k, v in st.session_state.candidate_info.items():
            st.markdown(f"**{k}:** {v}")

    with st.expander("ğŸ§¾ All Questions Asked"):
        for topic, qns in st.session_state.topic_questions:
            st.markdown(f"### ğŸ”¹ {topic}\n{qns}")
